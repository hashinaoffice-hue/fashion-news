import streamlit as st
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from email.utils import parsedate_to_datetime
from deep_translator import GoogleTranslator
import concurrent.futures

# [ëª¨ë°”ì¼ ìµœì í™” 1] ì‚¬ì´ë“œë°”ë¥¼ ì²˜ìŒì— ìˆ¨ê²¨ì„œ ì¢ì€ í™”ë©´ì„ ë„“ê²Œ ì“°ê²Œ í•¨
st.set_page_config(
    page_title="Fashion News", 
    page_icon="ğŸ§¥",
    layout="wide",
    initial_sidebar_state="collapsed" 
)

# --- CSSë¡œ ëª¨ë°”ì¼ì—ì„œ ë” ì•±ì²˜ëŸ¼ ë³´ì´ê²Œ ê¾¸ë¯¸ê¸° ---
st.markdown("""
    <style>
    /* í°íŠ¸ í¬ê¸° ì¡°ì • ë° ì—¬ë°± ìµœì í™” */
    .stButton>button {
        width: 100%;
        border-radius: 12px;
        height: 3em;
        font-weight: bold;
    }
    /* ë‰´ìŠ¤ ì¹´ë“œ ë””ìì¸ */
    div[data-testid="stContainer"] {
        background-color: #f9f9f9;
        padding: 15px;
        border-radius: 15px;
        margin-bottom: 10px;
    }
    /* ëª¨ë°”ì¼ì—ì„œ ë§í¬ ë²„íŠ¼ ì˜ ë³´ì´ê²Œ */
    a {
        text-decoration: none;
    }
    </style>
    """, unsafe_allow_html=True)

# -------------------------------------------------------------------
# ì‚¬ì´íŠ¸ ëª©ë¡
# -------------------------------------------------------------------
site_list = {
    "Hypebeast KR (í•˜ì…ë¹„ìŠ¤íŠ¸)": "https://news.google.com/rss/search?q=site:hypebeast.kr/fashion&hl=ko&gl=KR&ceid=KR:ko",
    "Dazed Digital (ë°ì´ì¦ˆë“œ)": "https://news.google.com/rss/search?q=site:dazeddigital.com/fashion&hl=en-US&gl=US&ceid=US:en",
    "Vogue US (ë³´ê·¸ ë¯¸êµ­)": "https://news.google.com/rss/search?q=site:vogue.com/fashion&hl=en-US&gl=US&ceid=US:en",
    "Highsnobiety (í•˜ì´ìŠ¤ë…¸ë°”ì´ì–´í‹°)": "https://news.google.com/rss/search?q=site:highsnobiety.com&hl=en-US&gl=US&ceid=US:en"
}

# -------------------------------------------------------------------
# ì‚¬ì´ë“œë°” (ì„¤ì •)
# -------------------------------------------------------------------
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • ë©”ë‰´")
    selected_site_name = st.radio("ì±„ë„ ì„ íƒ", list(site_list.keys()))
    st.write("---")
    enable_translation = st.toggle("ğŸ‡°ğŸ‡· ìë™ ë²ˆì—­", value=True)
    st.write("---")
    limit_option = st.slider("ê¸°ì‚¬ ê°œìˆ˜", 10, 50, 20)
    days_option = st.slider("ê¸°ê°„ (ì¼)", 1, 30, 7)
    st.info("ğŸ‘† ë©”ë‰´ë¥¼ ë‹«ìœ¼ë©´ í™”ë©´ì´ ë„“ì–´ì§‘ë‹ˆë‹¤.")

# -------------------------------------------------------------------
# í•¨ìˆ˜
# -------------------------------------------------------------------
def process_single_news(news_item):
    title = news_item['title']
    if " - " in title:
        title = title.rsplit(" - ", 1)[0]
    
    if enable_translation:
        try:
            # í•œê¸€ì´ í¬í•¨ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ë²ˆì—­
            if not any('\u3131' <= char <= '\u3163' or '\uac00' <= char <= '\ud7a3' for char in title):
                translator = GoogleTranslator(source='auto', target='ko')
                translated = translator.translate(title)
                if translated:
                    title = translated
        except:
            pass 
    news_item['title'] = title
    return news_item

# -------------------------------------------------------------------
# ë©”ì¸ í™”ë©´
# -------------------------------------------------------------------
# [ëª¨ë°”ì¼ ìµœì í™” 2] ì œëª©ì„ ê°„ê²°í•˜ê²Œ
st.title(f"ğŸ“± {selected_site_name.split('(')[0]}")
st.caption("ì™¼ìª½ ìƒë‹¨ í™”ì‚´í‘œ(>)ë¥¼ ëˆŒëŸ¬ ì„¤ì •ì„ ë³€ê²½í•˜ì„¸ìš”.")

# [ëª¨ë°”ì¼ ìµœì í™” 3] ì—„ì§€ì†ê°€ë½ìœ¼ë¡œ ëˆ„ë¥´ê¸° ì‰¬ìš´ í° ë²„íŠ¼
if st.button("ë‰´ìŠ¤ ìƒˆë¡œê³ ì¹¨ ğŸ”„", type="primary"):
    status_area = st.empty()
    status_area.info('ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...')
    
    try:
        rss_url = site_list[selected_site_name]
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(rss_url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        items = soup.find_all('item')
        
        raw_news_list = []
        for item in items:
            title_text = item.find('title').text
            if "Page " in title_text or "Category" in title_text: continue

            date_tag = item.find('pubdate')
            article_date_obj = datetime.now()
            display_date = ""
            is_recent = False
            
            if date_tag:
                try:
                    article_date_obj = parsedate_to_datetime(date_tag.text)
                    now = datetime.now(article_date_obj.tzinfo)
                    if (now - article_date_obj).days <= days_option:
                        is_recent = True
                        # ëª¨ë°”ì¼ì—ì„œëŠ” ë‚ ì§œë¥¼ ì§§ê²Œ í‘œì‹œ (2024-02-14)
                        display_date = article_date_obj.strftime("%Y-%m-%d")
                except:
                    is_recent = True 
            else:
                is_recent = True

            if is_recent:
                if item.find('link').next_sibling:
                    link = item.find('link').next_sibling.strip()
                else:
                    link = item.find('link').text
                if "/page/" in link: continue

                raw_news_list.append({
                    'title': title_text,
                    'link': link,
                    'date_str': display_date,
                    'real_date': article_date_obj 
                })

        raw_news_list.sort(key=lambda x: x['real_date'], reverse=True)
        target_news = raw_news_list[:limit_option]

        if target_news:
            final_news_list = []
            with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
                results = executor.map(process_single_news, target_news)
                for result in results:
                    final_news_list.append(result)
            
            status_area.empty() # ë¡œë”© ë¬¸êµ¬ ì‚­ì œ
            
            # [ëª¨ë°”ì¼ ìµœì í™” 4] ëª¨ë°”ì¼ì€ 1ì—´ë¡œ ë³´ëŠ” ê²Œ í¸í•˜ë¯€ë¡œ ì»¬ëŸ¼ ì œê±°
            for news in final_news_list:
                with st.container(border=True):
                    st.subheader(news['title'])
                    st.caption(f"ğŸ“… {news['date_str']}")
                    st.link_button("ê¸°ì‚¬ ì½ê¸° ğŸ‘‰", news['link'], use_container_width=True)
        else:
            status_area.warning("ìƒˆë¡œìš´ ì†Œì‹ì´ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        st.error(f"ì—ëŸ¬: {e}")